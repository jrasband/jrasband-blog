+++
title = "Introductory CS education misses the useful stuff"
author = ["Joshua Rasband"]
date = 2024-10-18
draft = false
+++

The most important things I've learned about how to use a computer were things
that I've had to teach myself.

My formal CS education consists of an AP class in high school, an
introductory-level CS class in college, and three computational physics labs. In
none of those classes did I learn about shell scripting, version control, or
package management.

Together, these three skills have opened up worlds of
productivity and possibility for me. They gave me the ability to write quick
scripts to move and rename files _en masse_, improved how I fix bugs and implement
features, and gave me access to a huge ecosystem of publicly available tools.

I think it's likely that this observation applies to formal education generally.
Rather than starting with the most useful things, formal education usually
starts with some theoretical fundamentals which are supposed to build up to
something useful (think "the mitochondria is the powerhouse of the cell"). Maybe
we need to consider inverting that structure, so that students first learn how
to do useful things, and then they can learn the foundational knowledge they'll
need as they want to improve their skills.
